{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushsinha/Project/Transformer/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/ayushsinha/Project/Transformer/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bpe_tokenizer as D\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"cfilt/iitb-english-hindi\")\n",
    "\n",
    "english_characters = list(string.ascii_lowercase) + list(string.ascii_uppercase)\n",
    "\n",
    "punctuation_list = list(string.punctuation)\n",
    "\n",
    "char_to_keep = english_characters + punctuation_list + [' ']\n",
    "\n",
    "def custom_filter(example):\n",
    "\n",
    "    for word in example['translation']['en']:\n",
    "        if word not in char_to_keep:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    for word in example['translation']['hi']:\n",
    "        if not ((ord(u'\\u0900') <= ord(word) <= ord(u'\\u097F') ) or (word in list(string.punctuation)) or (word == ' ')):\n",
    "            return False\n",
    "        \n",
    "    # removed sentences greater than 90th percentile     \n",
    "    if len(example['translation']['en']) > 161:\n",
    "        return False\n",
    "    \n",
    "    if len(example['translation']['hi']) > 115:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "ds_filtered = ds.filter(custom_filter)\n",
    "\n",
    "# corpus = ds_filtered['train']['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_en = ds_filtered['train'][0]['translation']['en']\n",
    "x_hi = ds_filtered['train'][0]['translation']['hi']\n",
    "\n",
    "x_en = [x_en]\n",
    "x_hi = [x_hi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = D.bpe_en_obj.base_vocab + ['<unk>', '<pad>']\n",
    "word2idx = {}\n",
    "for ind, ele in enumerate(all_tokens):\n",
    "    word2idx[ele] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "\n",
    "    res = D.bpe_en_obj.tokenize(x)\n",
    "    while len(res) < max_tokens:\n",
    "        res.append('<pad>')\n",
    "\n",
    "    \n",
    "    return torch.tensor([word2idx[ele] for ele in res])\n",
    "\n",
    "\n",
    "enc_input = torch.stack([tokenize(x) for x in x_en], dim = 0)\n",
    "\n",
    "# print([tokenize(x) for x in x_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = D.bpe_hin_obj.base_vocab + ['<unk>', '<pad>', '<eos>', '<start>']\n",
    "word2idx = {}\n",
    "for ind, ele in enumerate(all_tokens):\n",
    "    word2idx[ele] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(x):\n",
    "\n",
    "    res = D.bpe_hin_obj.tokenize(x)\n",
    "    key = 0\n",
    "    \n",
    "    while len(res) < max_tokens:\n",
    "\n",
    "        if not key:\n",
    "            res.insert(0, '<start>')\n",
    "            res.append('<eos>')\n",
    "            key = 1\n",
    "            continue\n",
    "\n",
    "        res.append('<pad>')\n",
    "    \n",
    "    return torch.tensor([word2idx[ele] for ele in res])\n",
    "\n",
    "dec_input = torch.stack([tokenize(x) for x in x_hi], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_output(x):\n",
    "    temp = []\n",
    "\n",
    "    for ele in x:\n",
    "        shifted_tensor = torch.roll(ele, shifts=-1, dims=-1)\n",
    "        shifted_tensor[-1] = 201\n",
    "        temp.append(shifted_tensor)\n",
    "\n",
    "    return torch.stack(temp, dim = 0)\n",
    "        \n",
    "\n",
    "target = make_target_output(dec_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3200, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enc_input\n",
    "# dec_input\n",
    "# target\n",
    "\n",
    "from decoder import decoder_stack\n",
    "from encoder import encoder_stack\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "enc = encoder_stack(4, 4, 512)\n",
    "\n",
    "enc_output = enc(enc_input)\n",
    "\n",
    "dec = decoder_stack(4, 4, 512, enc_output)\n",
    "\n",
    "output = dec(dec_input)\n",
    "\n",
    "output = output.reshape(-1, 204)\n",
    "target = target.reshape(-1)\n",
    "\n",
    "loss(output, target)\n",
    "# add the cross entropy loss function\n",
    "\n",
    "# do the backward pass\n",
    "\n",
    "# add batching logic\n",
    "\n",
    "# visualize training loss and see if its converging !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 204])\n",
      "torch.Size([1, 200])\n"
     ]
    }
   ],
   "source": [
    "# for ele in dec(dec_input)[0]:\n",
    "#     print(sum(ele))\n",
    "\n",
    "\n",
    "print(output.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9571, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# output, \n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 204])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.one_hot(target, num_classes= 204 ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(torch.empty(3, dtype=torch.long).random_(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 204])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  5,  42, 167, 160,   5,  40,  65, 182,  47,  75,  23, 160, 181, 160,\n",
       "         42,  57,  65,   2,  26,  40,  64,  47, 172, 160,  53, 180,  62, 166,\n",
       "         46, 160, 169, 160, 193,  45, 160,  38, 165, 202, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "        201, 201, 201, 201])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3190, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(torch.squeeze(output), torch.squeeze(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7054,  0.8946],\n",
      "        [ 0.2116, -2.9205]])\n",
      "tensor([-0.7054,  0.8946,  0.2116, -2.9205])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.randn(size = (2,2))\n",
    "\n",
    "print(temp)\n",
    "print(temp.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
