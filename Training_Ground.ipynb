{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushsinha/Project/Transformer/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/ayushsinha/Project/Transformer/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bpe_tokenizer as D\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"cfilt/iitb-english-hindi\")\n",
    "\n",
    "english_characters = list(string.ascii_lowercase) + list(string.ascii_uppercase)\n",
    "\n",
    "punctuation_list = list(string.punctuation)\n",
    "\n",
    "char_to_keep = english_characters + punctuation_list + [' ']\n",
    "\n",
    "def custom_filter(example):\n",
    "\n",
    "    for word in example['translation']['en']:\n",
    "        if word not in char_to_keep:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    for word in example['translation']['hi']:\n",
    "        if not ((ord(u'\\u0900') <= ord(word) <= ord(u'\\u097F') ) or (word in list(string.punctuation)) or (word == ' ')):\n",
    "            return False\n",
    "        \n",
    "    # removed sentences greater than 90th percentile     \n",
    "    if len(example['translation']['en']) > 161:\n",
    "        return False\n",
    "    \n",
    "    if len(example['translation']['hi']) > 115:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "ds_filtered = ds.filter(custom_filter)\n",
    "\n",
    "# corpus = ds_filtered['train']['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = D.bpe_en_obj.base_vocab + ['<unk>', '<pad>']\n",
    "word2idx_en = {}\n",
    "\n",
    "for ind, ele in enumerate(all_tokens):\n",
    "    word2idx_en[ele] = ind\n",
    "\n",
    "all_tokens = D.bpe_hin_obj.base_vocab + ['<unk>', '<pad>', '<eos>', '<start>']\n",
    "word2idx_hin = {}\n",
    "\n",
    "for ind, ele in enumerate(all_tokens):\n",
    "    word2idx_hin[ele] = ind\n",
    "\n",
    "def tokenize_en(x):\n",
    "\n",
    "    res = D.bpe_en_obj.tokenize(x)\n",
    "    while len(res) < max_tokens:\n",
    "        res.append('<pad>')\n",
    "\n",
    "    \n",
    "    return torch.tensor([word2idx_en[ele] for ele in res])\n",
    "\n",
    "def tokenize_hin(x):\n",
    "\n",
    "    res = D.bpe_hin_obj.tokenize(x)\n",
    "    key = 0\n",
    "    \n",
    "    while len(res) < max_tokens:\n",
    "\n",
    "        if not key:\n",
    "            res.insert(0, '<start>')\n",
    "            res.append('<eos>')\n",
    "            key = 1\n",
    "            continue\n",
    "\n",
    "        res.append('<pad>')\n",
    "    \n",
    "    return torch.tensor([word2idx_hin[ele] for ele in res])\n",
    "\n",
    "\n",
    "# enc_input = torch.stack([tokenize(x) for x in x_en], dim = 0)\n",
    "# dec_input = torch.stack([tokenize(x) for x in x_hi], dim = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1059018\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 348\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1189\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_from_disk\n",
    "# training_ds = load_from_disk('/Users/ayushsinha/Project/Transformer')\n",
    "training_ds = ds_filtered['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_en = ds_filtered['train'][0]['translation']['en']\n",
    "# x_hi = ds_filtered['train'][0]['translation']['hi']\n",
    "\n",
    "# x_en = [x_en]\n",
    "# x_hi = [x_hi]\n",
    "\n",
    "# type(ds)\n",
    "# ds_filtered['train'].map()\n",
    "\n",
    "# print(x_en)\n",
    "# print(x_hi)\n",
    "\n",
    "# all_tokens = D.bpe_en_obj.base_vocab + ['<unk>', '<pad>']\n",
    "# word2idx = {}\n",
    "# for ind, ele in enumerate(all_tokens):\n",
    "#     word2idx[ele] = ind\n",
    "\n",
    "# def tokenize(x):\n",
    "\n",
    "#     res = D.bpe_en_obj.tokenize(x)\n",
    "#     while len(res) < max_tokens:\n",
    "#         res.append('<pad>')\n",
    "\n",
    "    \n",
    "#     return torch.tensor([word2idx[ele] for ele in res])\n",
    "\n",
    "\n",
    "\n",
    "# enc_input = torch.stack([tokenize(x) for x in x_en], dim = 0)\n",
    "\n",
    "# all_tokens = D.bpe_hin_obj.base_vocab + ['<unk>', '<pad>', '<eos>', '<start>']\n",
    "# word2idx = {}\n",
    "# for ind, ele in enumerate(all_tokens):\n",
    "#     word2idx[ele] = ind\n",
    "\n",
    "\n",
    "# def tokenize(x):\n",
    "\n",
    "#     res = D.bpe_hin_obj.tokenize(x)\n",
    "#     key = 0\n",
    "    \n",
    "#     while len(res) < max_tokens:\n",
    "\n",
    "#         if not key:\n",
    "#             res.insert(0, '<start>')\n",
    "#             res.append('<eos>')\n",
    "#             key = 1\n",
    "#             continue\n",
    "\n",
    "#         res.append('<pad>')\n",
    "    \n",
    "#     return torch.tensor([word2idx[ele] for ele in res])\n",
    "\n",
    "# dec_input = torch.stack([tokenize(x) for x in x_hi], dim = 0)\n",
    "\n",
    "# training_ds = ds_filtered['train']\n",
    "\n",
    "# training_ds.save_to_disk('/Users/ayushsinha/Project/Transformer')\n",
    "\n",
    "# tokenized_iterable_dataset = iterable_dataset.map(lambda input: {'translation': {'en' : tokenize_en(input['translation']['en']) , 'hi' : tokenize_hin(input['translation']['hi'])}} )\n",
    "\n",
    "# def make_target_output(x):\n",
    "#     temp = []\n",
    "\n",
    "#     for ele in x:\n",
    "#         shifted_tensor = torch.roll(ele, shifts=-1, dims=-1)\n",
    "#         shifted_tensor[-1] = 201\n",
    "#         temp.append(shifted_tensor)\n",
    "\n",
    "#     return torch.stack(temp, dim = 0)\n",
    "        \n",
    "\n",
    "# target = make_target_output(dec_input)\n",
    "\n",
    "# target.shape\n",
    "\n",
    "# enc_input\n",
    "# dec_input\n",
    "# target\n",
    "\n",
    "# from decoder import decoder_stack\n",
    "# from encoder import encoder_stack\n",
    "\n",
    "# loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# enc = encoder_stack(4, 4, 512)\n",
    "\n",
    "# enc_output = enc(enc_input)\n",
    "\n",
    "# dec = decoder_stack(4, 4, 512, enc_output)\n",
    "\n",
    "# output = dec(dec_input)\n",
    "\n",
    "# output = output.reshape(-1, 204)\n",
    "# target = target.reshape(-1)\n",
    "\n",
    "# loss(output, target)\n",
    "# # add the cross entropy loss function\n",
    "\n",
    "# # do the backward pass\n",
    "\n",
    "# # add batching logic\n",
    "\n",
    "# # visualize training loss and see if its converging !\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable_dataset = training_ds.to_iterable_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mapper(x):\n",
    "    \n",
    "    en_tok = tokenize_en(x['translation']['en'])\n",
    "    hi_tok = tokenize_hin(x['translation']['hi'])\n",
    "    tar_tok = torch.roll(hi_tok, shifts=-1, dims=-1)\n",
    "    tar_tok[-1] = 201\n",
    "    return {'translation': {'en' : en_tok , 'hi' : hi_tok, 'tar': tar_tok}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_iterable_dataset = iterable_dataset.map(lambda input: custom_mapper(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from decoder import decoder_stack\n",
    "from encoder import encoder_stack\n",
    "\n",
    "class Transformer_MT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.mps_device = torch.device(\"mps\")\n",
    "        self.enc = encoder_stack(4, 4, 512).to(self.mps_device)\n",
    "    \n",
    "    def forward(self, enc_input, dec_input):\n",
    "\n",
    "        enc_output = self.enc(enc_input)\n",
    "        self.dec = decoder_stack(4, 4, 512).to(self.mps_device)\n",
    "\n",
    "        output = self.dec(dec_input, enc_output)\n",
    "\n",
    "        output = output.reshape(-1, 204)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer_MT()\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(tokenized_iterable_dataset, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x163fcebb0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = torch.tensor([1])\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    batch_size = 32\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    # size = \n",
    "    for batch, X in enumerate(dataloader):\n",
    "        # print(batch, X['translation']['en'][0], X['translation']['tar'][0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs_1 = X['translation']['en'].to(mps_device)\n",
    "        inputs_2 = X['translation']['hi'].to(mps_device)\n",
    "        model_output = model(inputs_1, inputs_2)\n",
    "\n",
    "        target = X['translation']['tar'].reshape(-1)\n",
    "        target = target.to(mps_device)\n",
    "        \n",
    "        loss = loss_fn(model_output, target)\n",
    "        \n",
    "        # print(loss)\n",
    "        # print(model_output.shape)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}, current: {current:>7f}\" )\n",
    "            torch.mps.empty_cache()\n",
    "\n",
    "    # shifted_tensor = torch.roll(X['translation']['en'], shifts=-1, dims=-1).clone()\n",
    "    # # shifted_tensor[:][-1] = 201\n",
    "   \n",
    "    # shifted_tensor[:][-1] = 201\n",
    "\n",
    "    # temp = shifted_tensor\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print (\"MPS device found!\")\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(mps_device)\n",
    "# data = data.to(mps_device)\n",
    "# labels = labels.to(mps_device) # If applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.319954, current: 1.000000\n",
      "loss: 5.317126, current: 321.000000\n",
      "loss: 5.319087, current: 641.000000\n",
      "loss: 5.316188, current: 961.000000\n",
      "loss: 5.319928, current: 1281.000000\n",
      "loss: 5.313426, current: 1601.000000\n",
      "loss: 5.318495, current: 1921.000000\n",
      "loss: 5.319056, current: 2241.000000\n",
      "loss: 5.319101, current: 2561.000000\n",
      "loss: 5.320077, current: 2881.000000\n",
      "loss: 5.320329, current: 3201.000000\n",
      "loss: 5.319688, current: 3521.000000\n",
      "loss: 5.320481, current: 3841.000000\n",
      "loss: 5.317501, current: 4161.000000\n",
      "loss: 5.317886, current: 4481.000000\n",
      "loss: 5.320276, current: 4801.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m mps_device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# size = \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, X \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(batch, X['translation']['en'][0], X['translation']['tar'][0])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m     inputs_1 \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(mps_device)\n",
      "File \u001b[0;32m~/Project/Transformer/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/Project/Transformer/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Project/Transformer/.venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:33\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Project/Transformer/.venv/lib/python3.9/site-packages/datasets/iterable_dataset.py:2032\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m formatter\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   2030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2032\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, example \u001b[38;5;129;01min\u001b[39;00m ex_iterable:\n\u001b[1;32m   2033\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[1;32m   2034\u001b[0m         \u001b[38;5;66;03m# `IterableDataset` automatically fills missing columns with None.\u001b[39;00m\n\u001b[1;32m   2035\u001b[0m         \u001b[38;5;66;03m# This is done with `_apply_feature_types_on_example`.\u001b[39;00m\n\u001b[1;32m   2036\u001b[0m         example \u001b[38;5;241m=\u001b[39m _apply_feature_types_on_example(\n\u001b[1;32m   2037\u001b[0m             example, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, token_per_repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_per_repo_id\n\u001b[1;32m   2038\u001b[0m         )\n",
      "File \u001b[0;32m~/Project/Transformer/.venv/lib/python3.9/site-packages/datasets/iterable_dataset.py:954\u001b[0m, in \u001b[0;36mMappedExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m key, formatter\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter()\n",
      "File \u001b[0;32m~/Project/Transformer/.venv/lib/python3.9/site-packages/datasets/iterable_dataset.py:1045\u001b[0m, in \u001b[0;36mMappedExamplesIterable._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     function_args\u001b[38;5;241m.\u001b[39mappend(current_idx)\n\u001b[1;32m   1044\u001b[0m transformed_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(example)  \u001b[38;5;66;03m# this will be updated with the function output\u001b[39;00m\n\u001b[0;32m-> 1045\u001b[0m transformed_example\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunction_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;66;03m# then we remove the unwanted columns\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_columns:\n",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(input)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_iterable_dataset \u001b[38;5;241m=\u001b[39m iterable_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m: \u001b[43mcustom_mapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mcustom_mapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_mapper\u001b[39m(x):\n\u001b[1;32m      3\u001b[0m     en_tok \u001b[38;5;241m=\u001b[39m tokenize_en(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m     hi_tok \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_hin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranslation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     tar_tok \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mroll(hi_tok, shifts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     tar_tok[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m201\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36mtokenize_hin\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_hin\u001b[39m(x):\n\u001b[0;32m---> 24\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbpe_hin_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m<\u001b[39m max_tokens:\n",
      "File \u001b[0;32m~/Project/Transformer/bpe.py:118\u001b[0m, in \u001b[0;36mBPE.tokenize\u001b[0;34m(self, sen)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m key:\n\u001b[1;32m    117\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    120\u001b[0m         couple \u001b[38;5;241m=\u001b[39m res[i] \u001b[38;5;241m+\u001b[39m res[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m couple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_rules:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(dataloader, model, loss, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['TORCH_SHOW_CPP_STACKTRACES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.9/site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.9/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.9/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1 is available.\n",
      "You should consider upgrading via the '/Users/ayushsinha/Project/Transformer/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)\n",
    "# !pip3 install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(dataloader, model, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = torch.nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "# output = loss(input, target)\n",
    "# print(torch.empty(3, dtype=torch.long).random_(5))\n",
    "# torch.squeeze(output).shape\n",
    "# torch.squeeze(target)\n",
    "# loss(torch.squeeze(output), torch.squeeze(target))\n",
    "# temp = torch.randn(size = (2,2))\n",
    "# print(temp)\n",
    "# print(temp.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7054,  0.8946],\n",
      "        [ 0.2116, -2.9205]])\n",
      "tensor([-0.7054,  0.8946,  0.2116, -2.9205])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
